# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mSlsirYEdpfY8uOqyVg6eFSe1rsq3r5s
"""

import joblib
import numpy as np
import matplotlib.pyplot as plt

from skimage.feature import haar_like_feature_coord
from skimage.feature import draw_haar_like_feature
from skimage.feature import haar_like_feature 
from skimage.transform import integral_image
import os
from cv2 import imshow
import cv2

import skimage
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
print(skimage.__version__)

from sklearn.datasets import fetch_lfw_people, fetch_lfw_pairs
lfw_people = fetch_lfw_people(min_faces_per_person=30, resize=1)

from tqdm import tqdm

def transformImg(image, cascadeWidth, cascadeHeight, array):
    image=cv2.resize(image, (cascadeWidth, cascadeHeight),interpolation = cv2.INTER_AREA)
    image = np.array(image)
    image = image.astype('float64')
    array.append(image)

def create_dataset(img_folder, cascadeWidth, cascadeHeight):
   
    img_data_array=[]
    class_name=[]
   

    for image_path in tqdm(os.listdir(img_folder)):
       
      image = cv2.imread(img_folder+image_path, cv2.IMREAD_GRAYSCALE) 
      h, w= image.shape
      hh = h//2
      wh = w//2
      try:

        i0 = image[:hh, :wh]
        transformImg(i0, cascadeWidth, cascadeHeight, img_data_array)
        i1 = image[hh:, :wh]
        transformImg(i1, cascadeWidth, cascadeHeight, img_data_array)
        i2 = image[:hh, wh:]
        transformImg(i2, cascadeWidth, cascadeHeight, img_data_array)
        i3 = image[:hh, :wh]
        transformImg(i3, cascadeWidth, cascadeHeight, img_data_array)
        
      except:
        pass


    return img_data_array

def getHaarFeatures(images, image_size, feature_coord, feature_type):

    V = np.empty((image_size, feature_coord.shape[0]))

    for index ,image in enumerate(tqdm(images)):

        ii = integral_image(image)

        f = haar_like_feature(ii, 0, 0, ii.shape[0], ii.shape[1],
                                    feature_type=feature_type,
                                    feature_coord=feature_coord)

        if(np.isnan(f).any() or np.isinf(f).any()):
            print("AAAAAAAAAAAAAAAAAAAa")
            print(f.shape)
            print(np.isnan(f).sum())   
            print(np.isposinf(f).sum()) 
            print(np.isneginf(f).sum()) 
            print(np.isinf(f).sum())    
        infs = np.isinf(f)
        if(infs.sum() > 0):
            inf_indices = np.where(infs == True)
            for pos in inf_indices:
                print("type")
                print(feature_type[pos])
                print("coord")
                print(feature_coord[pos])
        ##print(image.shape)
        ##print(image[0][:10])
        ##print(f[0:10])
        ##print("")
        #print(V.shape)
        V[index] = f
        #print(X[index][:10])
    return V

cascadeWidth = 24
cascadeHeight = 24

positive_image_size = 2300
negative_image_size = 8000

from skimage.transform import resize
negative_images = np.array(create_dataset("/content/drive/MyDrive/neg_imgs/NegativeImages/", cascadeWidth, cascadeHeight))
positive_images = lfw_people.images 



positive_images = resize(positive_images, (lfw_people.images.shape[0], cascadeWidth, cascadeHeight))

print(cascadeWidth)
print(cascadeHeight)
print(negative_images.shape)
print(positive_images.shape)

# negative_images_ = negative_images
# positive_images_ = positive_images

# negative_images = negative_images[:700]
# positive_images = positive_images[:700]

feature_coord, feature_type = \
    haar_like_feature_coord(width=cascadeWidth, height=cascadeHeight,
                            feature_type=None)


image_size = positive_image_size + negative_image_size

images = np.concatenate((positive_images[:positive_image_size], negative_images[:negative_image_size]))

X = getHaarFeatures(images, image_size, feature_coord, feature_type)
y = np.array([1] * positive_image_size + [0] * negative_image_size)

print(X.shape)

clf = RandomForestClassifier(n_estimators=1000, max_depth=None,
                             max_features=100, n_jobs=-1, random_state=0)

X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                    train_size=0.8,
                                                    random_state=0,
                                                    stratify=y)

X_train = X
y_train = y

clf.fit(X_train, y_train)
print("fit")
idx_sorted = np.argsort(clf.feature_importances_)[::-1]
cdf_feature_importances = np.cumsum(clf.feature_importances_[idx_sorted])
cdf_feature_importances /= cdf_feature_importances[-1]  # divide by max value
sig_feature_count = np.count_nonzero(cdf_feature_importances < 0.7)
sig_feature_percent = round(sig_feature_count /
                            len(cdf_feature_importances) * 100, 1)
print((f'{sig_feature_count} features, or {sig_feature_percent}%, '
       f'account for 70% of branch points in the random forest.'))

feature_coord_sel = feature_coord[idx_sorted[:sig_feature_count]]
feature_type_sel = feature_type[idx_sorted[:sig_feature_count]]


##image = draw_haar_like_feature(images[0], 0, 0, cascadeWidth + 1, cascadeHeight + 1, [feature_coord_sel[0]])
##plt.imshow(image)
##plt.show()

##print(feature_coord[:10])
##print(feature_type[:10])

#a = getHaarFeatures(images[0:1]/255, image_size, feature_coord, feature_type)
#print(a.shape)
#print(a[0][:10])

print(positive_images.shape)
print(negative_images.shape)
print(images.shape)

fig, axes = plt.subplots(2, 2)
for idx, ax in enumerate(axes.ravel()):
    image = images[int(positive_image_size/2)] / 255
    image = draw_haar_like_feature(image, 0, 0,
                                   images.shape[2],
                                   images.shape[1],
                                   [feature_coord[idx_sorted[idx]]])
    ax.imshow(image)
    ax.set_xticks([])
    ax.set_yticks([])

_ = fig.suptitle('The most important features')

print(feature_coord_sel.shape)
print(feature_type_sel.shape)

X = getHaarFeatures(images, image_size, feature_coord_sel, feature_type_sel)

X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                    train_size=0.8,
                                                    random_state=0,
                                                    stratify=y)

clf = RandomForestClassifier(n_estimators=1000, max_depth=None,
                             max_features=100, n_jobs=-1, random_state=0)

clf.fit(X_train, y_train)

print("fit")

modelTestSize = 50
images_test = np.concatenate((positive_images[positive_image_size:positive_image_size+modelTestSize], negative_images[negative_image_size:negative_image_size + modelTestSize]))

y = np.array([1] * modelTestSize + [0] * modelTestSize)

X = getHaarFeatures(images_test, modelTestSize + modelTestSize, feature_coord_sel, feature_type_sel)

print(clf.score(X, y))

FaceDetectorModel = {"feature_types" : feature_type_sel,
                     "feature_coord" : feature_coord_sel,
                     "classifier" : clf,
                     "cascade_size_x" : cascadeWidth,
                     "cascade_size_y" : cascadeHeight}

joblib.dump(FaceDetectorModel, "/content/drive/MyDrive/FaceDetectorModelP" + str(positive_image_size) + "N" + str(negative_image_size) + 
"W" + str(cascadeWidth) + "H" + str(cascadeHeight) + ".joblib")

print(positive_image_size)
print(negative_image_size)
print(np.concatenate((positive_images[positive_image_size:positive_image_size+50], negative_images[negative_image_size:negative_image_size + 50])).shape)
print(negative_images[negative_image_size:negative_image_size + 50].shape)
print(positive_images[positive_image_size:positive_image_size + 50].shape)
print(negative_images.shape)
print(positive_images.shape)

plt.imsave("pim.png",positive_images[0])